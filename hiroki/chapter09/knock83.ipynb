{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO9mqf0XEm8mRwWlHIKyiCo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"A0qM0U7Vzpr0"},"outputs":[],"source":["def collate_fn(batch):\n","    sequences = [x[0] for x in batch]\n","    labels = torch.LongTensor([x[1] for x in batch])\n","    x = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=PADDING_IDX)\n","    return x, labels\n","\n","# DataLoaderを作成\n","batch_size = 64\n","\n","train_dataloader = data.DataLoader(\n","            train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, worker_init_fn=seed_worker, generator=g)\n","valid_dataloader = data.DataLoader(\n","            valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, worker_init_fn=seed_worker, generator=g)\n","test_dataloader = data.DataLoader(\n","            test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, worker_init_fn=seed_worker, generator=g)\n","\n","dataloaders_dict = {'train': train_dataloader,\n","                    'val': valid_dataloader,\n","                    'test': test_dataloader,\n","                   }\n","\n","# 動作確認\n","batch_iter = iter(dataloaders_dict['train'])\n","inputs, labels = next(batch_iter)\n","print(inputs)\n","print(labels)"]},{"cell_type":"code","source":["# 学習を実行する\n","# 学習用の関数を定義\n","def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","\n","    # 初期設定\n","    # GPUが使えるか確認\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(torch.cuda.get_device_name())\n","    print(\"使用デバイス:\", device)\n","\n","    # ネットワークをgpuへ\n","    net.to(device)\n","\n","    train_loss = []\n","    train_acc = []\n","    valid_loss = []\n","    valid_acc = []\n","\n","    # epochのループ\n","    for epoch in range(num_epochs):\n","        # epochごとの学習と検証のループ\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                net.train() # 訓練モード\n","            else:\n","                net.eval() # 検証モード\n","\n","            epoch_loss = 0.0 # epochの損失和\n","            epoch_corrects = 0 # epochの正解数\n","\n","            # データローダーからミニバッチを取り出すループ\n","            for inputs, labels in dataloaders_dict[phase]:\n","                # GPUが使えるならGPUにおっくる\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                optimizer.zero_grad() # optimizerを初期化\n","\n","                # 順伝播計算(forward)\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = net(inputs)\n","                    loss = criterion(outputs, labels) # 損失を計算\n","                    _, preds = torch.max(outputs, 1) # ラベルを予想\n","\n","                    # 訓練時は逆伝播\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                    # イテレーション結果の計算\n","                    # lossの合計を更新\n","                    epoch_loss += loss.item() * inputs.size(0)\n","                    # 正解数の合計を更新\n","                    epoch_corrects += torch.sum(preds == labels.data)\n","\n","            # epochごとのlossと正解率の表示\n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n","            if phase == 'train':\n","                train_loss.append(epoch_loss)\n","                train_acc.append(epoch_acc.cpu())\n","            else:\n","                valid_loss.append(epoch_loss)\n","                valid_acc.append(epoch_acc.cpu())\n","\n","        print('Epoch {} / {} (train) Loss: {:.4f}, Acc: {:.4f}, (val) Loss: {:.4f}, Acc: {:.4f}'.format(epoch + 1, num_epochs, train_loss[-1], train_acc[-1], valid_loss[-1], valid_acc[-1]))\n","    return train_loss, train_acc, valid_loss, valid_acc\n","\n","# モデルの定義\n","net = RNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, HIDDEN_SIZE, OUTPUT_SIZE, NUM_LAYERS)\n","net.train()\n","\n","# 損失関数の定義\n","criterion = nn.CrossEntropyLoss()\n","\n","# 最適化手法の定義\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n","\n","num_epochs = 30\n","train_loss, train_acc, valid_loss, valid_acc = train_model(net,\n","            dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"],"metadata":{"id":"tndoNY0C1SBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_acc(net, dataloader):\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    net.eval()\n","    corrects = 0\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = net(inputs)\n","            _, preds = torch.max(outputs, 1) # ラベルを予想\n","            corrects += torch.sum(preds == labels.data).cpu()\n","    return corrects / len(dataloader.dataset)\n","\n","acc_train = calc_acc(net, train_dataloader)\n","acc_valid = calc_acc(net, valid_dataloader)\n","acc_test = calc_acc(net, test_dataloader)\n","print('学習データの正解率: {:.4f}'.format(acc_train))\n","print('検証データの正解率: {:.4f}'.format(acc_valid))\n","print('テストデータの正解率: {:.4f}'.format(acc_test))"],"metadata":{"id":"2TMmYsFaCaJs"},"execution_count":null,"outputs":[]}]}