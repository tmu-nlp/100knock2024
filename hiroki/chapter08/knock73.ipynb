{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMx6oCQ9wAXi6/7QyB+E9s7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FQunqfrkRC4A"},"outputs":[],"source":["# データセットを作成する\n","import torch.utils.data as data\n","\n","class NewsDataset(data.Dataset):\n","    \"\"\"\n","    newsのDatasetクラス\n","\n","    Attributes\n","    ----------------------------\n","    X : テンソル\n","        単語ベクトルの平均をまとめたテンソル\n","    y : テンソル\n","        カテゴリをラベル化したテンソル\n","    phase : 'train' or 'val'\n","        学習か訓練かを設定する\n","    \"\"\"\n","    def __init__(self, X, y, phase='train'):\n","        self.X = X\n","        self.y = y\n","        self.phase = phase\n","\n","    def __len__(self):\n","        \"\"\"全データサイズを返す\"\"\"\n","        return len(self.y)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"idxに対応するテンソル形式のデータとラベルを取得\"\"\"\n","        return self.X[idx], self.y[idx]\n","\n","train_dataset = NewsDataset(X_train, Y_train, phase='train')\n","valid_dataset = NewsDataset(X_valid, Y_valid, phase='val')\n","test_dataset = NewsDataset(X_test, Y_test, phase='val')\n","\n","# 動作確認\n","idx = 0\n","print(train_dataset.__getitem__(idx)[0].size())\n","print(train_dataset.__getitem__(idx)[1])\n","print(valid_dataset.__getitem__(idx)[0].size())\n","print(valid_dataset.__getitem__(idx)[1])\n","print(test_dataset.__getitem__(idx)[0].size())\n","print(test_dataset.__getitem__(idx)[1])"]},{"cell_type":"code","source":["# DataLoaderを作成\n","batch_size = 1\n","\n","train_dataloader = data.DataLoader(\n","            train_dataset, batch_size=batch_size, shuffle=True)\n","valid_dataloader = data.DataLoader(\n","            valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n","test_dataloader = data.DataLoader(\n","            test_dataset, batch_size=len(test_dataset), shuffle=False)\n","\n","dataloaders_dict = {'train': train_dataloader,\n","                    'val': valid_dataloader,\n","                    'test': test_dataloader,\n","                   }\n","\n","# 動作確認\n","batch_iter = iter(dataloaders_dict['train'])\n","inputs, labels = next(batch_iter)\n","print(inputs.size())\n","print(labels)"],"metadata":{"id":"Jp3CtYeBRjru"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","# 学習\n","\n","# モデルの定義\n","net = SLNet(300, 4)\n","net.train()\n","\n","# 損失関数の定義\n","criterion = nn.CrossEntropyLoss()\n","\n","# 最適化手法の定義\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n","\n","# 学習用の関数を定義\n","def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","\n","    # epochのループ\n","    for epoch in range(num_epochs):\n","        print('Epoch {} / {}'.format(epoch + 1, num_epochs))\n","        print('--------------------------------------------')\n","\n","        # epochごとの学習と検証のループ\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                net.train() # 訓練モード\n","            else:\n","                net.eval() # 検証モード\n","\n","            epoch_loss = 0.0 # epochの損失和\n","            epoch_corrects = 0 # epochの正解数\n","\n","            # データローダーからミニバッチを取り出すループ\n","            for inputs, labels in tqdm(dataloaders_dict[phase]):\n","                optimizer.zero_grad() # optimizerを初期化\n","\n","                # 順伝播計算(forward)\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = net(inputs)\n","                    loss = criterion(outputs, labels) # 損失を計算\n","                    _, preds = torch.max(outputs, 1) # ラベルを予想\n","\n","                    # 訓練時は逆伝播\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                    # イテレーション結果の計算\n","                    # lossの合計を更新\n","                    epoch_loss += loss.item() * inputs.size(0)\n","                    # 正解数の合計を更新\n","                    epoch_corrects += torch.sum(preds == labels.data)\n","\n","            # epochごとのlossと正解率の表示\n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n","\n","            print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","\n","# 学習を実行する\n","num_epochs = 10\n","train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"],"metadata":{"id":"nkdMmF5NRj1W"},"execution_count":null,"outputs":[]}]}