{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYGnVyPr1ahdufZUzc9mqw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NNbyszsZR3VN"},"outputs":[],"source":["# 学習用の関数を定義\n","def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","    train_loss = []\n","    train_acc = []\n","    valid_loss = []\n","    valid_acc = []\n","    # epochのループ\n","    for epoch in range(num_epochs):\n","        print('Epoch {} / {}'.format(epoch + 1, num_epochs))\n","        print('--------------------------------------------')\n","\n","        # epochごとの学習と検証のループ\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                net.train() # 訓練モード\n","            else:\n","                net.eval() # 検証モード\n","\n","            epoch_loss = 0.0 # epochの損失和\n","            epoch_corrects = 0 # epochの正解数\n","\n","            # データローダーからミニバッチを取り出すループ\n","            for inputs, labels in tqdm(dataloaders_dict[phase]):\n","                optimizer.zero_grad() # optimizerを初期化\n","\n","                # 順伝播計算(forward)\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = net(inputs)\n","                    loss = criterion(outputs, labels) # 損失を計算\n","                    _, preds = torch.max(outputs, 1) # ラベルを予想\n","\n","                    # 訓練時は逆伝播\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                    # イテレーション結果の計算\n","                    # lossの合計を更新\n","                    epoch_loss += loss.item() * inputs.size(0)\n","                    # 正解数の合計を更新\n","                    epoch_corrects += torch.sum(preds == labels.data)\n","\n","            # epochごとのlossと正解率の表示\n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n","            if phase == 'train':\n","                train_loss.append(epoch_loss)\n","                train_acc.append(epoch_acc)\n","            else:\n","                valid_loss.append(epoch_loss)\n","                valid_acc.append(epoch_acc)\n","\n","            print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","        # チェックポイントの保存\n","        torch.save({'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict()\n","                   },\n","                   './output/section8/checkpoint{}.pt'.format(epoch + 1))\n","    return train_loss, train_acc, valid_loss, valid_acc\n","\n","# 学習を実行する\n","\n","# モデルの定義\n","net = SLNet(300, 4)\n","net.train()\n","\n","# 損失関数の定義\n","criterion = nn.CrossEntropyLoss()\n","\n","# 最適化手法の定義\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n","\n","num_epochs = 10\n","train_loss, train_acc, valid_loss, valid_acc = train_model(net,\n","            dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"]}]}