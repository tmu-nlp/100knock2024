{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNaNkqgTiRHqki980Q7TzKN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6PgyUN2DlWI"},"outputs":[],"source":["import time\n","\n","# 学習用の関数を定義\n","def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","    train_loss = []\n","    train_acc = []\n","    valid_loss = []\n","    valid_acc = []\n","    # epochのループ\n","    for epoch in range(num_epochs):\n","        # 開始時刻の記録\n","        start = time.time()\n","        print('Epoch {} / {}'.format(epoch + 1, num_epochs))\n","        print('--------------------------------------------')\n","\n","        # epochごとの学習と検証のループ\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                net.train() # 訓練モード\n","            else:\n","                net.eval() # 検証モード\n","\n","            epoch_loss = 0.0 # epochの損失和\n","            epoch_corrects = 0 # epochの正解数\n","\n","            # データローダーからミニバッチを取り出すループ\n","            for inputs, labels in tqdm(dataloaders_dict[phase]):\n","                optimizer.zero_grad() # optimizerを初期化\n","\n","                # 順伝播計算(forward)\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = net(inputs)\n","                    loss = criterion(outputs, labels) # 損失を計算\n","                    _, preds = torch.max(outputs, 1) # ラベルを予想\n","\n","                    # 訓練時は逆伝播\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                    # イテレーション結果の計算\n","                    # lossの合計を更新\n","                    epoch_loss += loss.item() * inputs.size(0)\n","                    # 正解数の合計を更新\n","                    epoch_corrects += torch.sum(preds == labels.data)\n","\n","            # epochごとのlossと正解率の表示\n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n","            if phase == 'train':\n","                train_loss.append(epoch_loss)\n","                train_acc.append(epoch_acc)\n","            else:\n","                valid_loss.append(epoch_loss)\n","                valid_acc.append(epoch_acc)\n","\n","            print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","        # 修了時刻の記録\n","        end = time.time()\n","        calc_time = end - start\n","        print('batch_size {} calc_time: {:.4f} sec'.format(batch_size, calc_time))\n","    return train_loss, train_acc, valid_loss, valid_acc, calc_time\n","\n","\n","# 学習を実行する\n","batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n","cpu_times = []\n","for batch_size in batch_sizes:\n","    print('batch_size: {}'.format(batch_size))\n","    # DataLoaderを作成\n","    train_dataloader = data.DataLoader(\n","                train_dataset, batch_size=batch_size, shuffle=True)\n","    valid_dataloader = data.DataLoader(\n","                valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n","    test_dataloader = data.DataLoader(\n","                test_dataset, batch_size=len(test_dataset), shuffle=False)\n","\n","    dataloaders_dict = {'train': train_dataloader,\n","                        'val': valid_dataloader,\n","                        'test': test_dataloader,\n","                       }\n","    # モデルの定義\n","    net = SLNet(300, 4)\n","    net.train()\n","\n","    # 損失関数の定義\n","    criterion = nn.CrossEntropyLoss()\n","\n","    # 最適化手法の定義\n","    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n","\n","    num_epochs = 1\n","    train_loss, train_acc, valid_loss, valid_acc, calc_time = \\\n","                        train_model(net, dataloaders_dict, criterion, optimizer,\n","                                    num_epochs=num_epochs)\n","    cpu_times.append(calc_time)"]}]}