{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 45. 動詞の格パターンの抽出\n",
    "## 今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． \n",
    "## 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ． \n",
    "## ただし，出力は以下の仕様を満たすようにせよ．\n",
    "\n",
    "##  - 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "##  - 述語に係る助詞を格とする\n",
    "##  - 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "\n",
    "## 「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． \n",
    "## この文は「作り出す」という１つの動詞を含み，「作り出す」に係る文節は「ジョン・マッカーシーは」，「会議で」，「用語を」であると解析された場合は，次のような出力になるはずである．\n",
    "\n",
    "## 作り出す\tで は を\n",
    "\n",
    "## このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "## コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "## 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）\n",
    "\n",
    "import json\n",
    "from knock41 import sentences\n",
    "\n",
    "flag1 = False  # 動詞が見つかったらTrue\n",
    "flag2 = False  # 動詞に助詞がかかってたらTrue\n",
    "verb = ''\n",
    "cases = []\n",
    "results = []\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    for chunk in sentence.chunks:\n",
    "        if len(chunk.srcs) > 0:\n",
    "            for morph in chunk.morphs:\n",
    "                if morph.pos == '動詞':\n",
    "                    flag1 = True\n",
    "                    verb = morph.base\n",
    "                    break # 最左動詞をとるため\n",
    "            for s in chunk.srcs:\n",
    "                for morph in sentence.chunks[s].morphs:\n",
    "                    if morph.pos == '助詞':\n",
    "                        flag2 = True\n",
    "                        cases.append(morph.surface)\n",
    "        if flag1 and flag2:\n",
    "            #print(verb, ' '.join(cases), sep='\\t')\n",
    "            line = verb + \"\\t\" + ' '.join(cases)\n",
    "            results.append(line)\n",
    "        flag1 = False\n",
    "        flag2 = False\n",
    "        verb = ''\n",
    "        cases.clear()\n",
    "\n",
    "\n",
    "#print(results)\n",
    "with open(\"results.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for item in results:\n",
    "        file.write(item + \"\\n\")\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "!awk -F'\\t' '{print $1, $2}' results.txt | sed 's/[{}\"]//g' | tr -d ' ' | sort | uniq -c | sort -nr | head -n 10\n",
    "\n",
    " 49 するを\n",
    "  18 するが\n",
    "  15 するに\n",
    "  14 すると\n",
    "  12 するはを\n",
    "   9 よるに\n",
    "   8 行うを\n",
    "   6 基づくに\n",
    "   6 呼ぶと\n",
    "   6 するをに\n",
    "\n",
    "!grep -o \"行う\" results.txt | wc -l\n",
    "!grep -o \"なる\" results.txt | wc -l\n",
    "!grep -o \"与える\" results.txt | wc -l\n",
    "\n",
    "25\n",
    "28\n",
    "3\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaneko_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
