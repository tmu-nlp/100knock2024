{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "前処理の参考\n",
    "https://qiita.com/Hironsan/items/2466fe0f344115aff177\n",
    "https://torasenriwohashiru.hatenadiary.org/entry/20110806/1312558290\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "def preprocessing(txt_file):#txt_file：前処理対象のファイル\n",
    "    df_origin = pd.read_csv(txt_file,sep=\"\\t\")\n",
    "    df_prep = df_origin\n",
    "    for num in range (len(df_origin)):\n",
    "        text = df_origin[\"TITLE\"][num]#TITLEだけを前処理対象にする\n",
    "        t_prep = re.sub(re.compile('<.*?>'), '',text)#htmlタグ削除\n",
    "        t_prep = re.sub(r'[\\\"\\'.,:;\\(\\)#\\|\\*\\+\\!\\?#$%&/\\]\\[\\{\\}]', '', t_prep)#記号削除\n",
    "        t_prep = re.sub('[0-9]+', '', t_prep)#数字を削除\n",
    "        t_prep = re.sub(r\"-\",\"\",t_prep)#ハイフン削除\n",
    "        t_prep = t_prep.lower()#小文字化\n",
    "        t_prep = \" \".join([nltk.PorterStemmer().stem(t) for t in t_prep.split()])#ステミング(語幹の抽出)\n",
    "        df_prep[\"TITLE\"][num] = t_prep#処理後の文字列に置き換え\n",
    "\n",
    "    return df_prep\n",
    "\n",
    "#学習データ，検証データ，評価データそれぞれに前処理をする\n",
    "train_prep = preprocessing(\"train.txt\")\n",
    "valid_prep = preprocessing(\"valid.txt\")\n",
    "test_prep = preprocessing(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10672"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tf-idf実装の参考\n",
    "https://qiita.com/tsugar/items/0391c9a45842f9d9ae69\n",
    "\n",
    "tf-idf:文章中に含まれる単語の重要度を評価する指標\n",
    "tf:単語の出現頻度\n",
    "idf:単語の文書内における希少度\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "def make_features(train,valid,test):\n",
    "    \"\"\"\n",
    "    train,valid,test:それぞれ前処理済のdataframe\n",
    "    name：出力名\n",
    "    \"\"\"\n",
    "    df = pd.concat([train,valid,test],axis=0)#3つのdataframeを連結\n",
    "    #↑連結しておかないと使用している特徴量が一致しないので、入力の形式のエラーになる．\n",
    "    wc = CountVectorizer()#出現する単語のカウントを特徴量とする\n",
    "    x = wc.fit_transform(df[\"TITLE\"])\n",
    "    features = np.array(x.toarray())#numpy.ndarrayに変換\n",
    "    df_features = pd.DataFrame(features, columns=wc.get_feature_names_out())#get_feature_names_out:特徴量ラベル\n",
    "\n",
    "    #dataframeを3つに分けてreturnする\n",
    "    train_feature = df_features[:10672]#〜train\n",
    "    valid_feature = df_features[10672:12006]#train終わり〜valid\n",
    "    test_feature = df_features[12006:]#valid終わり〜\n",
    "\n",
    "    return train_feature.to_csv(\"train.feature.txt\",sep=\"\\t\",index=False),\\\n",
    "    valid_feature.to_csv(\"valid.feature.txt\",sep=\"\\t\",index=False),\\\n",
    "    test_feature.to_csv(\"test.feature.txt\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習データ，検証データ，評価データそれぞれの特徴量を抽出し出力する\n",
    "make_features(train_prep,valid_prep,test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "835e833e3fc08683878b4c51da562aefb7fad351900f35eb522834e1b1c3245e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
