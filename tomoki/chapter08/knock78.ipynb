{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObO6r3fenykWTtIDtkbEvk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vIZPFtvGvoC7"},"outputs":[],"source":["#No78(GPU上での活躍)\n","import torch\n","#時間の計測\n","import time\n","#データセットとデータローダ(データセットの中身をミニバッチごとに固めた集合)の作成に必要\n","from torch.utils.data import TensorDataset, DataLoader\n","#プログレスバーの表示\n","from tqdm import tqdm\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","torch.manual_seed(0)\n","#モデルの作成\n","class LogisticRegression(torch.nn.Module):\n","  #torch.nn.Moduleのサブクラス化(クラスの継承)\n","    def __init__(self):\n","        super().__init__()\n","        self.net = torch.nn.Sequential(torch.nn.Linear(300, 4),)\n","    def forward(self, X):\n","        return self.net(X)\n","\n","model = LogisticRegression()\n","X_train = torch.load(\"/content/drive/MyDrive/X_train.pt\")\n","y_train = torch.load(\"/content/drive/MyDrive/y_train.pt\")\n","X_valid = torch.load(\"/content/drive/MyDrive/X_valid.pt\")\n","y_valid = torch.load(\"/content/drive/MyDrive/y_valid.pt\")\n","#GPUを使うようにする\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#今までの結果を踏まえて学習率を0.01にする\n","optimizer = torch.optim.SGD(model.net.parameters(), lr=0.01)\n","#損失関数の定義\n","loss_fn = torch.nn.CrossEntropyLoss()\n","#batchsizeを２乗していく\n","batchsize = [2**i for i in range(5)]\n","#TensorDatasetを作成\n","ds = TensorDataset(X_train, y_train)\n","times = []\n","for bs in batchsize:\n","    #DataLoaderを作成\n","    loader = DataLoader(ds, batch_size=bs, shuffle=True)\n","    train_losses = []\n","    valid_losses = []\n","    train_accs = []\n","    valid_accs = []\n","\n","    for epoch in tqdm(range(10)):\n","      #時間の計測をスタートする\n","        start = time.time()\n","        for xx, yy in loader:\n","          #勾配の初期化\n","            optimizer.zero_grad()\n","            y_pred = model(X_train)\n","          #パラメータの更新\n","            loss = loss_fn(y_pred, y_train)\n","          #勾配を計算(逆伝播)\n","            loss.backward()\n","          #パラメータの更新\n","            optimizer.step()\n","\n","        #損失の記録\n","        train_losses.append(loss.detach().numpy())\n","        valid_losses.append(loss_fn(model(X_valid), y_valid).detach().numpy())\n","        #カテゴリの予測(指定した次元の最大値を返す)\n","        y_max_train, y_pred_train = torch.max(model(X_train),dim=1)\n","        y_max_valid, y_pred_valid = torch.max(model(X_valid),dim=1)\n","        #正解率の記録\n","        train_acc = accuracy_score(y_pred_train, y_train)\n","        valid_acc = accuracy_score(y_pred_valid, y_valid)\n","        train_accs.append(train_acc)\n","        valid_accs.append(valid_acc)\n","\n","        #学習時間計測\n","        times.append(time.time() - start)\n","\n","#計測時間を出力\n","with open (\"/content/drive/MyDrive/knock78output.txt\", \"w\") as f:\n","    for i in range(len(times)):\n","      #１０回ごとにバッチサイズを表示\n","        if i%10 == 0:\n","            print(f\"---------bachsize={2**(i/10)}----------\", file=f)\n","        #iは0から4をとる。余りを利用して、ephck1～10を表記する。\n","        print(f\"epoch{i%10+1}:{times[i]}\", file=f)"]}]}