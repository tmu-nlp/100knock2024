{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1iczpdKQktwdXjHw0GfYWC2pNfNuYJZ_-","authorship_tag":"ABX9TyO8SUs0gxaBvMjBa+UC+ECO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ggK4QyZ0K6wx","executionInfo":{"status":"ok","timestamp":1719377428818,"user_tz":-540,"elapsed":6029,"user":{"displayName":"Tomoki Kera","userId":"06617195934752380956"}},"outputId":"098d1d18-ab42-4e9a-d070-7e215158ad4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 1\n","to 2\n","in 3\n","on 4\n","UPDATE 5\n","The 6\n","as 7\n","for 8\n","To 9\n","of 10\n"]}],"source":["#No80(ID番号への変換)\n","import pandas as pd\n","import re\n","import numpy as np\n","# 前処理があまいところがあったので、作成し直す(NO50と同じ)\n","file = '/content/drive/MyDrive/newsCorpora.csv'\n","data = pd.read_csv(file, encoding='utf-8', header=None, sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n","data = data.replace('\"', \"'\")\n","# 特定のpublisherのみ抽出\n","publishers = ['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']\n","data = data.loc[data['PUBLISHER'].isin(publishers), ['TITLE', 'CATEGORY']].reset_index(drop=True)\n","\n","# 前処理\n","def preprocessing(text):\n","    text_clean = re.sub(r'[\\\"\\'.,:;\\(\\)#\\|\\*\\+\\!\\?#$%&/\\]\\[\\{\\}]', '', text)\n","    text_clean = re.sub('[0-9]+', '0', text_clean)\n","    text_clean = re.sub('\\s-\\s', ' ', text_clean)\n","    return text_clean\n","\n","data['TITLE'] = data['TITLE'].apply(preprocessing)\n","\n","# 学習用、検証用、評価用に分割する\n","from sklearn.model_selection import train_test_split\n","\n","train, valid_test = train_test_split(data, test_size=0.2, shuffle=True, random_state=64, stratify=data['CATEGORY'])\n","valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=64, stratify=valid_test['CATEGORY'])\n","\n","train = train.reset_index(drop=True)\n","valid = valid.reset_index(drop=True)\n","test = test.reset_index(drop=True)\n","\n","\n","# 単語の頻度\n","from collections import Counter\n","words = []\n","for text in train['TITLE']:\n","  #空文字で区切って、wordに追加していく\n","    for word in text.rstrip().split():\n","        words.append(word)\n","#数える\n","c = Counter(words)\n","#辞書の作成\n","word2id = {}\n","for i, cnt in enumerate(c.most_common()):\n","  ##出現頻度2回以上の単語のみ辞書に追加\n","    if cnt[1] > 1:\n","        word2id[cnt[0]] = i + 1\n","# 出現頻度上位10単語\n","for i, cnt in enumerate(word2id.items()):\n","    if i >= 10:\n","        break\n","    print(cnt[0], cnt[1])\n","# 単語のID化\n","def tokenizer(text):\n","    words = text.rstrip().split()\n","#単語辞書からそのwordのidを取得．ない場合は0を返す\n","    return [word2id.get(word, 0) for word in words]\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"pvWpoeVo04Jx"},"execution_count":null,"outputs":[]}]}