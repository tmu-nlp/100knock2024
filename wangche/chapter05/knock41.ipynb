{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f22e2cd",
   "metadata": {},
   "source": [
    "41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61cc4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morph:\n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        self.surface = surface  # 表層形\n",
    "        self.base = base        # 基本形\n",
    "        self.pos = pos          # 品詞\n",
    "        self.pos1 = pos1        # 品詞細分類1\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"surface: {self.surface}, base: {self.base}, pos: {self.pos}, pos1: {self.pos1}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a53eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, morphs=None, dst=-1):\n",
    "        self.morphs = morphs if morphs else []  # Morphオブジェクトのリスト\n",
    "        self.dst = dst  # 係り先文節インデックス番号\n",
    "        self.srcs = []  # 係り元文節インデックス番号のリスト\n",
    "\n",
    "    def __str__(self):\n",
    "        morphs_surface = ''.join([morph.surface for morph in self.morphs])\n",
    "        return f\"Chunk: {morphs_surface}, dst: {self.dst}, srcs: {self.srcs}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8995cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cabocha_output(parsed_file):\n",
    "    sentences = []\n",
    "    with open(parsed_file, 'r', encoding='utf-8') as f:\n",
    "        chunks = {}\n",
    "        chunk = None\n",
    "        for line in f:\n",
    "            if line == 'EOS\\n':\n",
    "                if chunk is not None:\n",
    "                    chunks[chunk_idx] = chunk\n",
    "                if chunks:\n",
    "                    sorted_chunks = sorted(chunks.items())\n",
    "                    sentence = [chunk for idx, chunk in sorted_chunks]\n",
    "                    for idx, chunk in sorted_chunks:\n",
    "                        if chunk.dst != -1:\n",
    "                            sentence[chunk.dst].srcs.append(idx)\n",
    "                    sentences.append(sentence)\n",
    "                chunks = {}\n",
    "                chunk = None\n",
    "            elif line[0] == '*':\n",
    "                if chunk is not None:\n",
    "                    chunks[chunk_idx] = chunk\n",
    "                cols = line.split(' ')\n",
    "                chunk_idx = int(cols[1])\n",
    "                dst = int(cols[2].rstrip('D'))\n",
    "                chunk = Chunk(dst=dst)\n",
    "            else:\n",
    "                surface, feature = line.split('\\t')\n",
    "                features = feature.split(',')\n",
    "                morph = Morph(surface, features[6], features[0], features[1])\n",
    "                chunk.morphs.append(morph)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d204805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 人工知能, Dst: 17\n",
      "Chunk: （じんこうちのう、、, Dst: 17\n",
      "Chunk: AI, Dst: 3\n",
      "Chunk: 〈エーアイ〉）とは、, Dst: 17\n",
      "Chunk: 「『計算, Dst: 5\n",
      "Chunk: （）』という, Dst: 9\n",
      "Chunk: 概念と, Dst: 9\n",
      "Chunk: 『コンピュータ, Dst: 8\n",
      "Chunk: （）』という, Dst: 9\n",
      "Chunk: 道具を, Dst: 10\n",
      "Chunk: 用いて, Dst: 12\n",
      "Chunk: 『知能』を, Dst: 12\n",
      "Chunk: 研究する, Dst: 13\n",
      "Chunk: 計算機科学, Dst: 14\n",
      "Chunk: （）の, Dst: 15\n",
      "Chunk: 一分野」を, Dst: 16\n",
      "Chunk: 指す, Dst: 17\n",
      "Chunk: 語。, Dst: -1\n"
     ]
    }
   ],
   "source": [
    "def display_first_sentence(parsed_file):\n",
    "    sentences = parse_cabocha_output(parsed_file)\n",
    "    if sentences:\n",
    "        first_sentence = sentences[0]\n",
    "        for chunk in first_sentence:\n",
    "            chunk_text = ''.join([morph.surface for morph in chunk.morphs])\n",
    "            print(f\"Chunk: {chunk_text}, Dst: {chunk.dst}\")\n",
    "\n",
    "parsed_file = 'ai.ja.txt.parsed'\n",
    "display_first_sentence(parsed_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9697e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
