{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520f639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Obtaining dependency information for optuna from https://files.pythonhosted.org/packages/15/da/68883911855d8b4d521f9a370e4e6aab8232b91c1d8d5a8348c4680c6642/optuna-3.6.1-py3-none-any.whl.metadata\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Obtaining dependency information for alembic>=1.5.0 from https://files.pythonhosted.org/packages/df/ed/c884465c33c25451e4a5cd4acad154c29e5341e3214e220e7f3478aa4b0d/alembic-1.13.2-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Obtaining dependency information for colorlog from https://files.pythonhosted.org/packages/f3/18/3e867ab37a24fdf073c1617b9c7830e06ec270b1ea4694a624038fc40a03/colorlog-6.8.2-py3-none-any.whl.metadata\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /Users/wenda/anaconda3/lib/python3.11/site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/wenda/anaconda3/lib/python3.11/site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /Users/wenda/anaconda3/lib/python3.11/site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in /Users/wenda/anaconda3/lib/python3.11/site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in /Users/wenda/anaconda3/lib/python3.11/site-packages (from optuna) (6.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/03/62/70f5a0c2dd208f9f3f2f9afd103aec42ee4d9ad2401d78342f75e9b8da36/Mako-1.3.5-py3-none-any.whl.metadata\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/wenda/anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/wenda/anaconda3/lib/python3.11/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/wenda/anaconda3/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c623a978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-01 13:51:52,287] A new study created in memory with name: no-name-2b508ec0-099a-40b8-81af-4faa0c8b700e\n",
      "[I 2024-07-01 14:07:25,321] Trial 0 finished with value: 0.6694152923538231 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'SGD'}. Best is trial 0 with value: 0.6694152923538231.\n",
      "[I 2024-07-01 14:13:09,656] Trial 1 finished with value: 0.7008995502248876 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:17:07,070] Trial 2 finished with value: 0.656671664167916 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:20:48,369] Trial 3 finished with value: 0.4160419790104948 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 4, 'activation': 'Sigmoid', 'optimizer_select': 'SGD'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:26:12,346] Trial 4 finished with value: 0.6874062968515742 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'SGD'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:30:40,390] Trial 5 finished with value: 0.4160419790104948 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'Sigmoid', 'optimizer_select': 'RMSprop'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:34:44,347] Trial 6 finished with value: 0.4160419790104948 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 2, 'activation': 'ReLU', 'optimizer_select': 'SGD'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:39:23,975] Trial 7 finished with value: 0.4782608695652174 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 2, 'activation': 'ReLU', 'optimizer_select': 'SGD'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:44:15,626] Trial 8 finished with value: 0.4160419790104948 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:48:15,680] Trial 9 finished with value: 0.658920539730135 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'SGD'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:51:28,835] Trial 10 finished with value: 0.46476761619190404 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Sigmoid', 'optimizer_select': 'RMSprop'}. Best is trial 1 with value: 0.7008995502248876.\n",
      "[I 2024-07-01 14:54:40,139] Trial 11 finished with value: 0.7076461769115442 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 11 with value: 0.7076461769115442.\n",
      "[I 2024-07-01 14:58:10,942] Trial 12 finished with value: 0.7031484257871065 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 11 with value: 0.7076461769115442.\n",
      "[I 2024-07-01 15:01:32,443] Trial 13 finished with value: 0.704647676161919 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 11 with value: 0.7076461769115442.\n",
      "[I 2024-07-01 15:05:06,545] Trial 14 finished with value: 0.7181409295352323 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:08:52,461] Trial 15 finished with value: 0.7023988005997002 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:12:17,504] Trial 16 finished with value: 0.6776611694152923 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 2, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:15:51,097] Trial 17 finished with value: 0.6859070464767616 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:19:32,250] Trial 18 finished with value: 0.7076461769115442 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:23:09,927] Trial 19 finished with value: 0.6709145427286357 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Sigmoid', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:26:35,579] Trial 20 finished with value: 0.6724137931034483 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 2, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:30:04,348] Trial 21 finished with value: 0.6851574212893553 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:33:25,691] Trial 22 finished with value: 0.6949025487256372 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:37:01,318] Trial 23 finished with value: 0.6836581709145427 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:40:26,513] Trial 24 finished with value: 0.6949025487256372 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:45:21,521] Trial 25 finished with value: 0.6619190404797601 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:48:59,095] Trial 26 finished with value: 0.7038980509745127 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:52:39,797] Trial 27 finished with value: 0.7031484257871065 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 15:56:19,237] Trial 28 finished with value: 0.6199400299850075 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 2, 'activation': 'Sigmoid', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:01:40,704] Trial 29 finished with value: 0.656671664167916 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:05:15,873] Trial 30 finished with value: 0.7083958020989505 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:08:53,528] Trial 31 finished with value: 0.7053973013493253 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:12:45,482] Trial 32 finished with value: 0.704647676161919 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:16:15,889] Trial 33 finished with value: 0.6979010494752623 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-01 16:19:59,643] Trial 34 finished with value: 0.6904047976011994 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:23:32,837] Trial 35 finished with value: 0.704647676161919 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:27:54,477] Trial 36 finished with value: 0.6679160419790104 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:31:44,157] Trial 37 finished with value: 0.6776611694152923 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Sigmoid', 'optimizer_select': 'SGD'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:35:57,232] Trial 38 finished with value: 0.6874062968515742 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:40:28,584] Trial 39 finished with value: 0.6506746626686657 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'SGD'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[I 2024-07-01 16:43:55,537] Trial 40 finished with value: 0.7038980509745127 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7181409295352323.\n",
      "[W 2024-07-01 16:44:33,884] Trial 41 failed with parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'Adam'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wenda/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/cf/glx3v3t12q7fcsb3x4qwt0r80000gn/T/ipykernel_84829/842147829.py\", line 218, in objective_CNN\n",
      "    score = train_model(X_train, Y_train, X_test, Y_test, BATCH_SIZE, model, lr, NUM_EPOCHS, device, optimizer_select)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cf/glx3v3t12q7fcsb3x4qwt0r80000gn/T/ipykernel_84829/842147829.py\", line 127, in train_model\n",
      "    loss.backward()\n",
      "  File \"/Users/wenda/anaconda3/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/Users/wenda/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-07-01 16:44:33,899] Trial 41 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 222\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n\u001b[1;32m    221\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 222\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective_CNN, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m81\u001b[39m)\n\u001b[1;32m    223\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective_RNN, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m    224\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective_LSTM, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[1;32m     63\u001b[0m             study,\n\u001b[1;32m     64\u001b[0m             func,\n\u001b[1;32m     65\u001b[0m             n_trials,\n\u001b[1;32m     66\u001b[0m             timeout,\n\u001b[1;32m     67\u001b[0m             catch,\n\u001b[1;32m     68\u001b[0m             callbacks,\n\u001b[1;32m     69\u001b[0m             gc_after_trial,\n\u001b[1;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[3], line 218\u001b[0m, in \u001b[0;36mobjective_CNN\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    216\u001b[0m optimizer_select \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_select\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSGD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSprop\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    217\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN(VOCAB_SIZE, EMB_SIZE, OUTPUT_SIZE, layer, unit, activation)\n\u001b[0;32m--> 218\u001b[0m score \u001b[38;5;241m=\u001b[39m train_model(X_train, Y_train, X_test, Y_test, BATCH_SIZE, model, lr, NUM_EPOCHS, device, optimizer_select)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "Cell \u001b[0;32mIn[3], line 127\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, X_test, y_test, batch_size, model, lr, num_epochs, device, collate_fn, optimizer_select)\u001b[0m\n\u001b[1;32m    125\u001b[0m         Y_pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m    126\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(Y_pred, Y)\n\u001b[0;32m--> 127\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    128\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    129\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, dw, dh, output):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, dw, padding_idx=vocab_size-1)\n",
    "        self.rnn = nn.RNN(dw, dh, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(dh*2, output, bias=True)\n",
    "        self.fc2 = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        _, x = self.rnn(x)\n",
    "        rnn_out = torch.cat([x[-2,:,:], x[-1,:,:]], dim=1)\n",
    "        x = self.fc1(rnn_out)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, dw, dh, output):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, dw, padding_idx=vocab_size-1)\n",
    "        self.lstm = nn.LSTM(dw, dh, batch_first=True,bidirectional=True)\n",
    "        self.fc1 = nn.Linear(dh*2, output, bias=True)\n",
    "        self.fc2 = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        _, x = self.lstm(x)\n",
    "        x = torch.cat([x[0][0],x[0][1]], dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self, vocab_size, dw, output, layer, unit, activation):\n",
    "      super().__init__()\n",
    "      self.layer = layer\n",
    "      self.embed = nn.Embedding(vocab_size, dw, padding_idx = vocab_size-1)\n",
    "      if unit == 6:\n",
    "          units = [6, 4, 2]\n",
    "      elif unit == 4:\n",
    "          units = [4, 3, 2]\n",
    "      elif unit == 2:\n",
    "          units = [2, 2, 2]\n",
    "      self.conv1 = nn.Conv2d(1, units[0], kernel_size=(units[0], 300))\n",
    "      linearoutput = units[0]\n",
    "      if layer > 1:\n",
    "          self.conv2 = nn.Conv2d(units[0], units[1], kernel_size=(units[1],1))\n",
    "          linearoutput = units[1]\n",
    "      if layer > 2:\n",
    "          self.conv3 = nn.Conv2d(units[1], units[2], kernel_size=(units[2],1))\n",
    "          linearoutput = units[2]\n",
    "      self.fc1 = nn.Linear(linearoutput, output, bias=True)\n",
    "      self.fc2 = nn.Softmax(dim=1)\n",
    "\n",
    "      if activation == \"Tanh\":\n",
    "          self.active = nn.Tanh()\n",
    "      elif activation == \"ReLU\":\n",
    "          self.active = nn.ReLU()\n",
    "      elif activation == \"Sigmoid\":\n",
    "          self.active = nn.Sigmoid()\n",
    "  def forward(self, x):\n",
    "      x = self.embed(x)\n",
    "      x = x.unsqueeze(1)\n",
    "      x = self.conv1(x)\n",
    "      x = self.active(x)\n",
    "      if self.layer > 1:\n",
    "          x = self.conv2(x)\n",
    "          x = self.active(x)\n",
    "      if self.layer > 2:\n",
    "          x = self.conv3(x)\n",
    "          x = self.active(x)\n",
    "      x = F.max_pool2d(x, kernel_size=(x.size()[2], 1))\n",
    "      x = x.view(x.size()[0], -1)\n",
    "      x = self.fc1(x)\n",
    "      x = self.fc2(x)\n",
    "      return x\n",
    "\n",
    "def calculate_loss_and_accuracy(model, dataset, device, criterion=None):\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            Y_pred = model(X)\n",
    "            if criterion != None:\n",
    "                loss += criterion(Y_pred, Y).item()\n",
    "            pred = torch.argmax(Y_pred, dim=-1)\n",
    "            total += len(Y)\n",
    "            correct += (pred == Y).sum().item()\n",
    "    return loss / len(dataset), correct / total\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test, batch_size, model, lr, num_epochs, device, collate_fn=None, optimizer_select=\"SGD\"):\n",
    "    dataset_train = TensorDataset(X_train, y_train)\n",
    "    dataset_test = TensorDataset(X_test, y_test)\n",
    "    model = model.to(device)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(device)\n",
    "    for ep in range(num_epochs):\n",
    "        if ep%20==0:\n",
    "            lr = lr * 0.1\n",
    "        if optimizer_select == \"SGD\":\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        elif optimizer_select == \"Adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        elif optimizer_select == \"RMSprop\":\n",
    "          optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "        model.train()\n",
    "        for X, Y in dataloader_train:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            Y_pred = model(X)\n",
    "            loss = criterion(Y_pred, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    model.eval()\n",
    "    _, acc_test = calculate_loss_and_accuracy(model, dataset_test, device, criterion=criterion)\n",
    "\n",
    "    return acc_test\n",
    "\n",
    "\n",
    "def CountVocab(name):\n",
    "    f = open(\"{}_code.txt\".format(name), \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    max_num = []\n",
    "    for line in lines:\n",
    "        line_t = line.split(\"\\t\")[2].replace(\"\\n\", \"\").split(\" \")\n",
    "        max_num.extend(map(int, line_t))\n",
    "    vocab_max = max(max_num)+1\n",
    "    return vocab_max\n",
    "\n",
    "def GetCodeLow(name):\n",
    "    f = open(\"{}_code.txt\".format(name), \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    num_list = []\n",
    "    code_list = []\n",
    "    pad_list = []\n",
    "    for line in lines:\n",
    "        line_s = line.split(\"\\t\")\n",
    "        code_list.append(int(line_s[0]))\n",
    "        num = line_s[2].replace(\"\\n\", \"\").split(\" \")\n",
    "        num = list(map(int, num))\n",
    "        num_list.append(num)\n",
    "        num_tensor = torch.tensor(num)\n",
    "        pad_list.append(num_tensor)\n",
    "    max_vocab = CountVocab(\"train\")\n",
    "    mlen = max([len(x) for x in num_list])\n",
    "    pad_list = list(map(lambda x:x + [max_vocab]*(mlen-len(x)), num_list))\n",
    "    pad_list = torch.tensor(pad_list)\n",
    "    code_list = torch.tensor(code_list)\n",
    "    return pad_list, code_list\n",
    "\n",
    "def objective_RNN(trial):\n",
    "    X_train, Y_train = GetCodeLow(\"train\")\n",
    "    X_test, Y_test = GetCodeLow(\"test\")\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_EPOCHS = 10\n",
    "    VOCAB_SIZE = CountVocab(\"train\")+1\n",
    "    EMB_SIZE = 300\n",
    "    OUTPUT_SIZE = 4\n",
    "    lr = 1e-2\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_name_display_only = trial.suggest_categorical(\"model_name_RNN\", [\"RNN\"])\n",
    "    HIDDEN_SIZE = trial.suggest_categorical(\"HIDDEN_SIZE\", [10, 50, 100, 500, 1000])\n",
    "    optimizer_select = trial.suggest_categorical(\"optimizer_select\", [\"SGD\", \"Adam\", \"RMSprop\"])\n",
    "    model = RNN(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    score = train_model(X_train, Y_train, X_test, Y_test, BATCH_SIZE, model, lr, NUM_EPOCHS, device, optimizer_select)\n",
    "    return score\n",
    "\n",
    "def objective_LSTM(trial):\n",
    "    X_train, Y_train = GetCodeLow(\"train\")\n",
    "    X_test, Y_test = GetCodeLow(\"test\")\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_EPOCHS = 10\n",
    "    VOCAB_SIZE = CountVocab(\"train\")+1\n",
    "    EMB_SIZE = 300\n",
    "    OUTPUT_SIZE = 4\n",
    "    lr = 1e-2\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_name_display_only = trial.suggest_categorical(\"model_name_LSTM\", [\"LSTM\"])\n",
    "    HIDDEN_SIZE = trial.suggest_categorical(\"HIDDEN_SIZE\", [10, 50, 100, 500, 1000])\n",
    "    optimizer_select = trial.suggest_categorical(\"optimizer_select\", [\"SGD\", \"Adam\", \"RMSprop\"])\n",
    "    model = LSTM(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    score = train_model(X_train, Y_train, X_test, Y_test, BATCH_SIZE, model, lr, NUM_EPOCHS, device, optimizer_select)\n",
    "    return score\n",
    "\n",
    "def objective_CNN(trial):\n",
    "    X_train, Y_train = GetCodeLow(\"train\")\n",
    "    X_test, Y_test = GetCodeLow(\"test\")\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_EPOCHS = 10\n",
    "    VOCAB_SIZE = CountVocab(\"train\")+1\n",
    "    EMB_SIZE = 300\n",
    "    OUTPUT_SIZE = 4\n",
    "    lr = 1e-2\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_name_display_only = trial.suggest_categorical(\"model_name_CNN\", [\"CNN\"])\n",
    "    layer = trial.suggest_categorical(\"layer\", [1,2,3])\n",
    "    unit = trial.suggest_categorical(\"unit\", [2,4,6])\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"Tanh\", \"Sigmoid\", \"ReLU\"])\n",
    "    optimizer_select = trial.suggest_categorical(\"optimizer_select\", [\"SGD\", \"Adam\", \"RMSprop\"])\n",
    "    model = CNN(VOCAB_SIZE, EMB_SIZE, OUTPUT_SIZE, layer, unit, activation)\n",
    "    score = train_model(X_train, Y_train, X_test, Y_test, BATCH_SIZE, model, lr, NUM_EPOCHS, device, optimizer_select)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_CNN, n_trials=81)\n",
    "study.optimize(objective_RNN, n_trials=15)\n",
    "study.optimize(objective_LSTM, n_trials=15)\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f977d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
