{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(1)\n",
    "train_X = torch.load(\"./train_X.pt\")\n",
    "train_Y = torch.load(\"./train_Y.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# nn.Moduleを継承してモデルを作成\n",
    "class Perseptron(nn.Module):\n",
    "  def __init__(self, input_size, output_size) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    # nn.Linear: 全結合層を作成する\n",
    "    self.fc = nn.Linear(input_size, output_size, bias=False)\n",
    "\n",
    "    # 重み行列を正規分布に上書き\n",
    "    nn.init.normal_(self.fc.weight, 0.0, 1.0)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return torch.softmax(self.fc(x), dim=-1)\n",
    "  \n",
    "model = Perseptron(train_X.size()[1], 4)\n",
    "model.load_state_dict(torch.load(\"./knock71.model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.382736086845398\n",
      "grad: tensor([[ 0.0133, -0.0079, -0.0042,  ...,  0.0023,  0.0052,  0.0038],\n",
      "        [-0.0047,  0.0028,  0.0015,  ..., -0.0008, -0.0018, -0.0013],\n",
      "        [-0.0068,  0.0040,  0.0021,  ..., -0.0012, -0.0027, -0.0019],\n",
      "        [-0.0018,  0.0011,  0.0006,  ..., -0.0003, -0.0007, -0.0005]])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss1 = loss_fn(model(train_X[1]), train_Y[1])\n",
    "\n",
    "model.zero_grad()\n",
    "loss1.backward()\n",
    "\n",
    "print(f\"loss: {loss1}\")\n",
    "print(f\"grad: {model.fc.weight.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.4035048484802246\n",
      "grad: tensor([[ 8.9731e-03,  6.2788e-03, -1.6555e-03,  ..., -2.1846e-03,\n",
      "         -8.0510e-03,  1.0024e-02],\n",
      "        [ 1.4332e-04,  1.2115e-03,  1.6096e-03,  ..., -6.4464e-05,\n",
      "          7.5581e-04, -1.0738e-03],\n",
      "        [-6.7723e-03, -3.5095e-03, -1.9894e-03,  ...,  8.2629e-05,\n",
      "          8.9476e-04, -1.1709e-03],\n",
      "        [-2.3441e-03, -3.9808e-03,  2.0353e-03,  ...,  2.1664e-03,\n",
      "          6.4004e-03, -7.7793e-03]])\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss4 = loss_fn(model(train_X[:4]), train_Y[:4])\n",
    "\n",
    "model.zero_grad()\n",
    "loss4.backward()\n",
    "\n",
    "print(f\"loss: {loss4}\")\n",
    "print(f\"grad: {model.fc.weight.grad}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
