{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBwjUe9DIaLjt1j6aXdB6k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BKNOm78moMFv"},"outputs":[],"source":["#58. 正則化パラメータの変更\n","#ロジスティック回帰モデルを学習するとき，正則化パラメータを調整することで，学習時の過学習（overfitting）の度合いを制御できる．\n","#異なる正則化パラメータでロジスティック回帰モデルを学習し，学習データ，検証データ，および評価データ上の正解率を求めよ．\n","#実験の結果は，正則化パラメータを横軸，正解率を縦軸としたグラフにまとめよ．\n","\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","import pickle\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","\n","\n","def score_lr(lr, x):\n","    return [np.max(lr.predict_proba(x), axis=1), lr.predict(x)]\n","\n","\n","def learning_model(x_train, y_train, c):\n","    lr = LogisticRegression(random_state=20010101, max_iter=1000, C=c)\n","    lr.fit(x_train, y_train)\n","    model_name = \"logreg\" + str(c) + \".pkl\"\n","    with open(model_name, \"wb\") as f:\n","        pickle.dump(lr, f)\n","    return lr\n","\n","\n","def open_model(c):\n","    model_name = \"logreg\" + str(c) + \".pkl\"\n","    with open(model_name, \"rb\") as f:\n","        model = pickle.load(f)\n","    return model\n","\n","\n","if __name__ == \"__main__\":\n","    X_train = pd.read_table(\"train.feature.txt\")\n","    X_valid = pd.read_table(\"valid.feature.txt\")\n","    X_test = pd.read_table(\"test.feature.txt\")\n","    Y_train = pd.read_table(\"train.txt\")[\"CATEGORY\"]\n","    Y_valid = pd.read_table(\"valid.txt\")[\"CATEGORY\"]\n","    Y_test = pd.read_table(\"test.txt\")[\"CATEGORY\"]\n","    train = pd.read_table(\"train.txt\")\n","    valid = pd.read_table(\"valid.txt\")\n","    test = pd.read_table(\"test.txt\")\n","    # 逆数が正則化項に対応するのに注意\n","    regular = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n","    train_acu = []\n","    valid_acu = []\n","    test_acu = []\n","    for c in regular:\n","        # model = learning_model(X_train, Y_train, c)\n","        model = open_model(c)\n","        train_pred = score_lr(model, X_train)\n","        valid_pred = score_lr(model, X_valid)\n","        test_pred = score_lr(model, X_test)\n","        train_acu.append(accuracy_score(train[\"CATEGORY\"], train_pred[1]))\n","        valid_acu.append(accuracy_score(valid[\"CATEGORY\"], valid_pred[1]))\n","        test_acu.append(accuracy_score(test[\"CATEGORY\"], test_pred[1]))\n","    plt.plot(regular, train_acu,  marker=\"o\", color=\"red\", label=\"train\")\n","    plt.plot(regular, valid_acu,  marker=\"o\", color=\"blue\", label=\"valid\")\n","    plt.plot(regular, test_acu,  marker=\"o\", color=\"green\", label=\"test\")\n","    plt.xscale(\"log\")\n","    plt.xlabel(\"C\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.savefig(\"regular_parameter\")"]}]}