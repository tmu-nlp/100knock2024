{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJhqxmMOoKebwHuUA42hSU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#76. チェックポイント\n","#問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，\n","#チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．\n","\n","#from knock72 import *  # 必要なカスタムモジュールをインポート\n","from torch.utils.data import Dataset  # データセットの定義に必要\n","from torch.utils.data import DataLoader  # データローダの定義に必要\n","from matplotlib import pyplot as plt  # プロット用\n","import numpy as np  # 数値計算用\n","\n","# シングルレイヤーのパーセプトロンネットワークモデルを定義\n","model = SingleLayerPerceptronNetwork(300, 4)\n","\n","# 損失関数としてクロスエントロピー損失を使用\n","criterion = nn.CrossEntropyLoss()\n","\n","# 確率的勾配降下法（SGD）オプティマイザを使用し、学習率を設定\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n","\n","# エポック数（トレーニングの反復回数）を20に設定\n","num_epochs = 20\n","\n","# トレーニングと検証のログを記録するリストを初期化\n","log_train = []\n","log_valid = []\n","\n","# エポックごとにトレーニングを実行\n","for epoch in range(num_epochs):\n","    model.train()  # モデルをトレーニングモードに設定\n","    loss_train = 0.0  # トレーニング損失を初期化\n","    for inputs, labels in dataloader_train:  # トレーニングデータローダからバッチごとにデータを取得\n","        optimizer.zero_grad()  # 勾配をゼロに初期化\n","\n","        outputs = model(inputs)  # モデルの出力を計算\n","        loss = criterion(outputs, labels)  # 損失を計算\n","        loss.backward()  # 逆伝播を実行して勾配を計算\n","        optimizer.step()  # オプティマイザをステップ実行してモデルパラメータを更新\n","\n","    # トレーニングデータに対する損失と精度を計算\n","    loss_train, acc_train = calc_loss_acc(model, criterion, dataloader_train)\n","\n","    # 検証データに対する損失と精度を計算\n","    loss_valid, acc_valid = calc_loss_acc(model, criterion, dataloader_valid)\n","\n","    # トレーニングと検証の結果をログに記録\n","    log_train.append([loss_train, acc_train])\n","    log_valid.append([loss_valid, acc_valid])\n","\n","    # モデルの状態をチェックポイントとして保存\n","    torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(\n","    ), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n","\n","    # エポックごとのトレーニングと検証の損失および精度を表示\n","    print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}')\n"],"metadata":{"id":"UxOV4izd8Znk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719814982841,"user_tz":-540,"elapsed":202173,"user":{"displayName":"Mio Ohashi","userId":"10520922308048209533"}},"outputId":"42308b1d-6697-40ae-de13-9e5918eee783"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 0.3359, accuracy_train: 0.8839, loss_valid: 0.3251, accuracy_valid: 0.8906\n","epoch: 2, loss_train: 0.2931, accuracy_train: 0.9023, loss_valid: 0.2920, accuracy_valid: 0.8996\n","epoch: 3, loss_train: 0.2714, accuracy_train: 0.9097, loss_valid: 0.2691, accuracy_valid: 0.9018\n","epoch: 4, loss_train: 0.2591, accuracy_train: 0.9126, loss_valid: 0.2641, accuracy_valid: 0.9025\n","epoch: 5, loss_train: 0.2526, accuracy_train: 0.9171, loss_valid: 0.2583, accuracy_valid: 0.9055\n","epoch: 6, loss_train: 0.2469, accuracy_train: 0.9170, loss_valid: 0.2592, accuracy_valid: 0.9048\n","epoch: 7, loss_train: 0.2417, accuracy_train: 0.9196, loss_valid: 0.2535, accuracy_valid: 0.9123\n","epoch: 8, loss_train: 0.2375, accuracy_train: 0.9192, loss_valid: 0.2484, accuracy_valid: 0.9130\n","epoch: 9, loss_train: 0.2352, accuracy_train: 0.9203, loss_valid: 0.2509, accuracy_valid: 0.9130\n","epoch: 10, loss_train: 0.2351, accuracy_train: 0.9194, loss_valid: 0.2464, accuracy_valid: 0.9145\n","epoch: 11, loss_train: 0.2300, accuracy_train: 0.9198, loss_valid: 0.2470, accuracy_valid: 0.9153\n","epoch: 12, loss_train: 0.2282, accuracy_train: 0.9231, loss_valid: 0.2469, accuracy_valid: 0.9100\n","epoch: 13, loss_train: 0.2262, accuracy_train: 0.9234, loss_valid: 0.2479, accuracy_valid: 0.9160\n","epoch: 14, loss_train: 0.2248, accuracy_train: 0.9234, loss_valid: 0.2457, accuracy_valid: 0.9153\n","epoch: 15, loss_train: 0.2243, accuracy_train: 0.9253, loss_valid: 0.2477, accuracy_valid: 0.9123\n","epoch: 16, loss_train: 0.2231, accuracy_train: 0.9245, loss_valid: 0.2481, accuracy_valid: 0.9168\n","epoch: 17, loss_train: 0.2243, accuracy_train: 0.9230, loss_valid: 0.2527, accuracy_valid: 0.9108\n","epoch: 18, loss_train: 0.2240, accuracy_train: 0.9256, loss_valid: 0.2566, accuracy_valid: 0.9115\n","epoch: 19, loss_train: 0.2199, accuracy_train: 0.9273, loss_valid: 0.2502, accuracy_valid: 0.9153\n","epoch: 20, loss_train: 0.2200, accuracy_train: 0.9267, loss_valid: 0.2498, accuracy_valid: 0.9123\n"]}]}]}