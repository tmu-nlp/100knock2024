{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOt3WHPMnzINLRnkF4Z/1Fa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"eoSnjvL6NH0n","executionInfo":{"status":"error","timestamp":1719819112774,"user_tz":-540,"elapsed":10,"user":{"displayName":"Mio Ohashi","userId":"10520922308048209533"}},"outputId":"05afa680-7081-430c-ca4d-5eed511d1eec"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid character '，' (U+FF0C) (<ipython-input-1-8b9d4ca7f488>, line 3)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8b9d4ca7f488>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    問題77のコードを改変し，GPU上で学習を実行せよ．\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '，' (U+FF0C)\n"]}],"source":["#78. GPU上での学習\n","#問題77のコードを改変し，GPU上で学習を実行せよ．\n","from torch import nn\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import time\n","\n","# シンプルな単層パーセプトロンネットワークを定義\n","class SingleLayerPerceptronNetwork(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        # 全結合層を定義\n","        self.fc = nn.Linear(input_size, output_size, bias=False)\n","        # 重みの初期化\n","        nn.init.normal_(self.fc.weight, 0.0, 1.0)\n","\n","    def forward(self, x):\n","        x = self.fc(x)\n","        return x\n","\n","# トレーニングデータをロード\n","X_train = torch.load(\"X_train.pt\")\n","\n","# モデルを初期化\n","model = SingleLayerPerceptronNetwork(300, 4)\n","\n","# モデルの予測値をソフトマックス関数を適用して計算\n","y_hat_1 = torch.softmax(model(X_train[:1]), dim=-1)\n","Y_hat = torch.softmax(model.forward(X_train[:4]), dim=-1)\n","\n","# ニュースデータセットを定義するクラス\n","class NewsDataset(Dataset):\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","    def __getitem__(self, idx):\n","        return [self.x[idx], self.y[idx]]\n","\n","# モデルの精度を計算する関数\n","def calc_acc(model, loader):\n","    model.eval()\n","    total = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            outputs = model(inputs)\n","            pred = torch.argmax(outputs, dim=-1)\n","            total += len(inputs)\n","            correct += (pred == labels).sum().item()\n","\n","        return correct / total\n","\n","# モデルの損失と精度を計算する関数（デバイス対応）\n","def calc_loss_acc(model, criterion, loader, device):\n","    model.eval()\n","    loss = 0.0\n","    total = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs = inputs.to(device)  # デバイスに移動\n","            labels = labels.to(device)  # デバイスに移動\n","            outputs = model(inputs)\n","            loss += criterion(outputs, labels).item()\n","            pred = torch.argmax(outputs, dim=-1)\n","            total += len(inputs)\n","            correct += (pred == labels).sum().item()\n","\n","        return loss / len(loader), correct / total\n","\n","# トレーニング、バリデーション、テストデータをロード\n","X_train = torch.load(\"X_train.pt\")\n","X_valid = torch.load(\"X_valid.pt\")\n","X_test = torch.load(\"X_test.pt\")\n","y_train = torch.load(\"y_train.pt\")\n","y_valid = torch.load(\"y_valid.pt\")\n","y_test = torch.load(\"y_test.pt\")\n","\n","# データセットを作成\n","dataset_train = NewsDataset(X_train, y_train)\n","dataset_valid = NewsDataset(X_valid, y_valid)\n","dataset_test = NewsDataset(X_test, y_test)\n","\n","# データローダーを作成\n","dataloader_train = DataLoader(dataset_train, batch_size=1, shuffle=True)\n","dataloader_valid = DataLoader(dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n","dataloader_test = DataLoader(dataset_test, batch_size=len(dataset_test), shuffle=False)\n","\n","# 損失関数を定義\n","criterion = nn.CrossEntropyLoss()\n","\n","# 損失を計算してバックプロパゲーションを行う\n","l_1 = criterion(model(X_train[:1]), y_train[:1])\n","model.zero_grad()\n","l_1.backward()\n","\n","l = criterion(model(X_train[:4]), y_train[:4])\n","model.zero_grad()\n","l.backward()\n","\n","# モデルをトレーニングする関数\n","def train_model(dataset_train, dataset_valid, batch_size, model, criterion, num_epochs, device=None):\n","    model.to(device)  # モデルをデバイスに移動\n","\n","    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n","    dataloader_valid = DataLoader(dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n","\n","    log_train = []\n","    log_valid = []\n","\n","    for epoch in range(num_epochs):\n","        start_time = time.time()\n","\n","        model.train()\n","        loss_train = 0.0\n","        for inputs, labels in dataloader_train:\n","            optimizer.zero_grad()\n","\n","            inputs = inputs.to(device)  # 入力をデバイスに移動\n","            labels = labels.to(device)  # ラベルをデバイスに移動\n","            outputs = model.forward(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","        end_time = time.time()\n","\n","        # トレーニングデータとバリデーションデータでの損失と精度を計算\n","        loss_train, acc_train = calc_loss_acc(model, criterion, dataloader_train, device)\n","        loss_valid, acc_valid = calc_loss_acc(model, criterion, dataloader_valid, device)\n","        log_train.append([loss_train, acc_train])\n","        log_valid.append([loss_valid, acc_valid])\n","\n","        # モデルのチェックポイントを保存\n","        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n","\n","        print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}, train_time: {(end_time - start_time):.4f}sec')\n","\n","# モデルとその他のパラメータを定義\n","model = SingleLayerPerceptronNetwork(300, 4)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n","num_epochs = 1\n","\n","# CUDAが利用可能かどうかをチェックし、デバイスを指定\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# バッチサイズごとにモデルをトレーニング\n","for batch_size in [2 ** i for i in range(12)]:\n","    print(f\"batch_size : {batch_size}\")\n","    train_model(dataset_train, dataset_valid, batch_size, model, criterion, num_epochs, device)\n"]}]}