{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGtCn6BzL2L/JHp7zWOmWR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0WniIyKONzYe"},"outputs":[],"source":["from knock72 import *  # 必要な関数やクラスをインポートしていると仮定\n","from torch.utils.data import Dataset  # Datasetクラスをtorch.utils.dataからインポート\n","from torch.utils.data import DataLoader  # DataLoaderクラスをtorch.utils.dataからインポート\n","from matplotlib import pyplot as plt  # matplotlibのpyplotをインポート\n","import numpy as np  # numpyをインポート\n","import time  # 時間計測のためにtimeモジュールをインポート\n","\n","# モデルをトレーニングする関数\n","def train_model(dataset_train, dataset_valid, batch_size, model, criterion, num_epochs):\n","    # トレーニング用データローダーの作成\n","    dataloader_train = DataLoader(\n","        dataset_train, batch_size=batch_size, shuffle=True)\n","    # バリデーション用データローダーの作成\n","    dataloader_valid = DataLoader(\n","        dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n","\n","    log_train = []  # トレーニングデータのログを保存するリスト\n","    log_valid = []  # バリデーションデータのログを保存するリスト\n","\n","    for epoch in range(num_epochs):  # エポックの数だけ繰り返す\n","        start_time = time.time()  # エポックの開始時間を記録\n","\n","        model.train()  # モデルをトレーニングモードに設定\n","        loss_train = 0.0  # トレーニングロスの初期化\n","        for inputs, labels in dataloader_train:  # トレーニングデータローダーからバッチを取得\n","            optimizer.zero_grad()  # オプティマイザの勾配をゼロにリセット\n","\n","            outputs = model(inputs)  # モデルに入力を与えて出力を取得\n","            loss = criterion(outputs, labels)  # 出力とラベルからロスを計算\n","            loss.backward()  # 誤差逆伝播を実行\n","            optimizer.step()  # パラメータの更新\n","        end_time = time.time()  # エポックの終了時間を記録\n","\n","        # トレーニングデータに対するロスと精度を計算\n","        loss_train, acc_train = calc_loss_acc(\n","            model, criterion, dataloader_train)\n","        # バリデーションデータに対するロスと精度を計算\n","        loss_valid, acc_valid = calc_loss_acc(\n","            model, criterion, dataloader_valid)\n","        log_train.append([loss_train, acc_train])  # トレーニングログに追加\n","        log_valid.append([loss_valid, acc_valid])  # バリデーションログに追加\n","\n","        # モデルとオプティマイザの状態を保存\n","        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(\n","        ), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n","\n","        # エポックごとの結果を出力\n","        print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}, train_time: {(end_time - start_time):.4f}sec')\n","\n","# モデルの定義と設定\n","model = SingleLayerPerceptronNetwork(300, 4)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n","num_epochs = 1\n","\n","# バッチサイズを変更しながらモデルをトレーニング\n","for batch_size in [2 ** i for i in range(12)]:\n","    print(f\"batch_size : {batch_size}\")\n","    train_model(dataset_train, dataset_valid,\n","                batch_size, model, criterion, num_epochs)\n","\n","\"\"\"\n","結果の例:\n","batch_size : 1\n","epoch: 1, loss_train: 0.3263, accuracy_train: 0.8896, loss_valid: 0.3279, accuracy_valid: 0.8892, train_time: 0.4831sec\n","batch_size : 2\n","epoch: 1, loss_train: 0.3013, accuracy_train: 0.8969, loss_valid: 0.3120, accuracy_valid: 0.8952, train_time: 0.3185sec\n","...\n","batch_size : 2048\n","epoch: 1, loss_train: 0.2861\n"]}]}