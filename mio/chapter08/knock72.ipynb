{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyODlozQ7Sphr/ey2b9l7ud4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#knock72\n","from torch import nn\n","import torch\n","#from knock71 import *\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","\n","class NewsDataset(Dataset):\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","    def __getitem__(self, idx):\n","        return [self.x[idx], self.y[idx]]\n","\n","\n","def calc_acc(model, loader):\n","    model.eval()\n","    total = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            outputs = model(inputs)\n","            pred = torch.argmax(outputs, dim=-1)\n","            total += len(inputs)\n","            correct += (pred == labels).sum().item()\n","\n","        return correct / total\n","\n","\n","def calc_loss_acc(model, criterion, loader):\n","    model.eval()\n","    loss = 0.0\n","    total = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            outputs = model(inputs)\n","            loss += criterion(outputs, labels).item()\n","            pred = torch.argmax(outputs, dim=-1)\n","            total += len(inputs)\n","            correct += (pred == labels).sum().item()\n","\n","        return loss / len(loader), correct / total\n","\n","\n","X_train = torch.load(\"X_train.pt\")\n","X_valid = torch.load(\"X_valid.pt\")\n","X_test = torch.load(\"X_test.pt\")\n","y_train = torch.load(\"y_train.pt\")\n","y_valid = torch.load(\"y_valid.pt\")\n","y_test = torch.load(\"y_test.pt\")\n","\n","dataset_train = NewsDataset(X_train, y_train)\n","dataset_valid = NewsDataset(X_valid, y_valid)\n","dataset_test = NewsDataset(X_test, y_test)\n","\n","dataloader_train = DataLoader(dataset_train, batch_size=1, shuffle=True)\n","dataloader_valid = DataLoader(\n","    dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n","dataloader_test = DataLoader(\n","    dataset_test, batch_size=len(dataset_test), shuffle=False)\n","\n","criterion = nn.CrossEntropyLoss()\n","l_1 = criterion(model(X_train[:1]), y_train[:1])\n","model.zero_grad()\n","l_1.backward()\n","# print(f'loss: {l_1:.4f}')\n","# print(f'grad:\\n{model.fc.weight.grad}')\n","\n","l = criterion(model(X_train[:4]), y_train[:4])\n","model.zero_grad()\n","l.backward()"],"metadata":{"id":"zAc13K6d5k1n"},"execution_count":null,"outputs":[]}]}