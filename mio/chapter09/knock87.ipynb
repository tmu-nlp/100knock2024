{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otL2VrmvZX_R"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "87. 確率的勾配降下法によるCNNの学習\n",
        "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，問題86で構築したモデルを学習せよ．訓練データ上の損失と正解率，評価データ上の損失と正解率を表示しながらモデルを学習し，適当な基準（例えば10エポックなど）で終了させよ．\n",
        "\"\"\"\n",
        "class Padseq():\n",
        "  def __init__(self, padding_idx):\n",
        "    self.padding_idx = padding_idx\n",
        "\n",
        "  def __call__(self, batch):\n",
        "    sorted_batch = sorted(batch, key=lambda x: x['inputs'].shape[0], reverse=True)\n",
        "    sequences = [x['inputs'] for x in sorted_batch]\n",
        "    sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=self.padding_idx)\n",
        "    labels = torch.LongTensor([x['labels'] for x in sorted_batch])\n",
        "\n",
        "    return {'inputs': sequences_padded, 'labels': labels}\n",
        "\n",
        "VOCAB_SIZE = len(set(w2id.id_dict.values())) + 1\n",
        "EMB_SIZE = 300\n",
        "PADDING_IDX = len(set(w2id.id_dict.values()))\n",
        "OUTPUT_SIZE = 4\n",
        "OUT_CHANNELS = 100\n",
        "KERNEL_HEIGHTS = 3\n",
        "STRIDE = 1\n",
        "PADDING = 1\n",
        "LEARNING_RATE = 5e-2\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "#def __init__(self, hidden_size, vocab_size, emb_size, pad_idx, output_size, device, num_layers, emb_weight=None, bidirectional=False):\n",
        "model = CNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, OUT_CHANNELS, KERNEL_HEIGHTS, STRIDE, PADDING, emb_weights=weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "log = train_model(dataset_train, dataset_valid, BATCH_SIZE, model, criterion, optimizer, NUM_EPOCHS, device=device, collate_fn=Padseq(PADDING_IDX))\n",
        "\n",
        "visualize_logs(log)\n",
        "_, acc_train = calc_loss_acc(model, dataset_train,device)\n",
        "_, acc_test = calc_loss_acc(model, dataset_test,device)\n",
        "print(f'accuracy (train)：{acc_train:.3f}')\n",
        "print(f'accuracy (test)：{acc_test:.3f}')\n",
        "\n"
      ]
    }
  ]
}